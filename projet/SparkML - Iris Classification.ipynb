{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "edd85861",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark\n",
    "from pyspark import SparkContext\n",
    "from pyspark.sql import Row\n",
    "from pyspark.sql import SQLContext\n",
    "from pyspark import SparkFiles\n",
    "import os\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e9c6a23b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-19 20:19:48,602 WARN util.Utils: Your hostname, HPCAI10 resolves to a loopback address: 127.0.1.1; using 192.168.1.85 instead (on interface wifi0)\n",
      "2022-02-19 20:19:48,604 WARN util.Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    }
   ],
   "source": [
    "\"\"\" RESOLVE SPARK CONTEXT ERROR\n",
    "export PYTHONPATH=$SPARK_HOME/python:$SPARK_HOME/python/lib/py4j-0.10.9-src.zip:$PYTHONPATH\n",
    "export PATH=$SPARK_HOME/bin:$SPARK_HOME/python:$PATH\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "\"\"\"----------------------------------------------------------------------------\n",
    "CREATE SPARK CONTEXT\n",
    "CREATE SQL CONTEXT\n",
    "----------------------------------------------------------------------------\"\"\"\n",
    "sc =SparkContext()\n",
    "sqlContext = SQLContext(sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b931ab58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "\"\"\"df1 = sqlContext.range(2, 10000000, 2)\n",
    "df2 = sqlContext.range(2, 10000000, 4)\n",
    "step1 = df1.repartition(5)\n",
    "step12 = df2.repartition(6)\n",
    "step2 = step1.selectExpr(\"id * 5 as id\")\n",
    "step3 = step2.join(step12, [\"id\"])\n",
    "step4 = step3.selectExpr(\"sum(id)\")\n",
    "step4.collect() # 2500000000000\"\"\"\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "63de2dd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir=\"\"\n",
    "file = os.path.join(data_dir,\"iris.csv\")\n",
    "if os.path.isfile(file):\n",
    "    panda_df = pd.read_csv(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f97e7e4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- sepal_length: double (nullable = true)\n",
      " |-- sepal_width: double (nullable = true)\n",
      " |-- petal_length: double (nullable = true)\n",
      " |-- petal_width: double (nullable = true)\n",
      " |-- variety: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "iris_df=sqlContext.createDataFrame(panda_df)\n",
    "iris_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "432fe066",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import StringIndexer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b1028074",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "stringIndexer = StringIndexer(inputCol=\"variety\", outputCol=\"ind_variety\")\n",
    "\"\"\"Error raise Exception((\"Python in worker has different version %s than that in \" +\n",
    "Exception: Python in worker has different version 3.9 than that in driver 3.8, \n",
    "PySpark cannot run with different minor versions\"\"\"\n",
    "# créer environnement python 3.9\n",
    "si_model = stringIndexer.fit(iris_df) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7a9906c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- sepal_length: double (nullable = true)\n",
      " |-- sepal_width: double (nullable = true)\n",
      " |-- petal_length: double (nullable = true)\n",
      " |-- petal_width: double (nullable = true)\n",
      " |-- variety: string (nullable = true)\n",
      " |-- ind_variety: double (nullable = false)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "irisNormDf = si_model.transform(iris_df)\n",
    "irisNormDf.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f8ee4af6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[Row(variety='Virginica', ind_variety=2.0),\n",
       " Row(variety='Versicolor', ind_variety=1.0),\n",
       " Row(variety='Setosa', ind_variety=0.0)]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "irisNormDf.select(\"variety\",\"ind_variety\").distinct().collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4356fadc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 4:>                                                          (0 + 8) / 8]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------------------+------------------+------------------+------------------+---------+------------------+\n",
      "|summary|      sepal_length|       sepal_width|      petal_length|       petal_width|  variety|       ind_variety|\n",
      "+-------+------------------+------------------+------------------+------------------+---------+------------------+\n",
      "|  count|               150|               150|               150|               150|      150|               150|\n",
      "|   mean| 5.843333333333334|3.0573333333333332|3.7580000000000005|1.1993333333333331|     null|               1.0|\n",
      "| stddev|0.8280661279778632|0.4358662849366984| 1.765298233259466|0.7622376689603464|     null|0.8192319205190405|\n",
      "|    min|               4.3|               2.0|               1.0|               0.1|   Setosa|               0.0|\n",
      "|    max|               7.9|               4.4|               6.9|               2.5|Virginica|               2.0|\n",
      "+-------+------------------+------------------+------------------+------------------+---------+------------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "\"\"\"--------------------------------------------------------------------------\n",
    "Perform Data Analytics\n",
    "-------------------------------------------------------------------------\"\"\"\n",
    "\n",
    "#See standard parameters\n",
    "irisNormDf.describe().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "00cf204c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.linalg import Vectors\n",
    "def transformToLabeledPoint(row) :\n",
    "    lp = ( row[\"variety\"], row[\"ind_variety\"], \\\n",
    "                Vectors.dense([row[\"sepal_length\"],\\\n",
    "                        row[\"sepal_width\"], \\\n",
    "                        row[\"petal_length\"], \\\n",
    "                        row[\"petal_width\"]]))\n",
    "    return lp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "be39350b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "irisLp = irisNormDf.rdd.map(transformToLabeledPoint)\n",
    "irisLpDf = sqlContext.createDataFrame(irisLp,[\"species\",\"label\", \"features\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7ac4509a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 7:>                                                          (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----+-----------------+\n",
      "|species|label|         features|\n",
      "+-------+-----+-----------------+\n",
      "| Setosa|  0.0|[5.1,3.5,1.4,0.2]|\n",
      "| Setosa|  0.0|[4.9,3.0,1.4,0.2]|\n",
      "| Setosa|  0.0|[4.7,3.2,1.3,0.2]|\n",
      "| Setosa|  0.0|[4.6,3.1,1.5,0.2]|\n",
      "| Setosa|  0.0|[5.0,3.6,1.4,0.2]|\n",
      "| Setosa|  0.0|[5.4,3.9,1.7,0.4]|\n",
      "| Setosa|  0.0|[4.6,3.4,1.4,0.3]|\n",
      "| Setosa|  0.0|[5.0,3.4,1.5,0.2]|\n",
      "| Setosa|  0.0|[4.4,2.9,1.4,0.2]|\n",
      "| Setosa|  0.0|[4.9,3.1,1.5,0.1]|\n",
      "+-------+-----+-----------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DataFrame[species: string, label: double, features: vector]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "irisLpDf.select(\"species\",\"label\",\"features\").show(10)\n",
    "irisLpDf.cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "512a9038",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(species='Setosa', label=0.0, features=DenseVector([4.6, 3.1, 1.5, 0.2])),\n",
       " Row(species='Setosa', label=0.0, features=DenseVector([4.8, 3.4, 1.6, 0.2])),\n",
       " Row(species='Setosa', label=0.0, features=DenseVector([4.9, 3.1, 1.5, 0.1])),\n",
       " Row(species='Setosa', label=0.0, features=DenseVector([5.4, 3.7, 1.5, 0.2])),\n",
       " Row(species='Setosa', label=0.0, features=DenseVector([4.6, 3.6, 1.0, 0.2])),\n",
       " Row(species='Setosa', label=0.0, features=DenseVector([5.0, 3.0, 1.6, 0.2])),\n",
       " Row(species='Setosa', label=0.0, features=DenseVector([5.0, 3.2, 1.2, 0.2])),\n",
       " Row(species='Setosa', label=0.0, features=DenseVector([5.4, 3.4, 1.5, 0.4])),\n",
       " Row(species='Setosa', label=0.0, features=DenseVector([4.4, 3.2, 1.3, 0.2])),\n",
       " Row(species='Setosa', label=0.0, features=DenseVector([5.0, 3.5, 1.3, 0.3])),\n",
       " Row(species='Setosa', label=0.0, features=DenseVector([5.1, 3.4, 1.5, 0.2])),\n",
       " Row(species='Setosa', label=0.0, features=DenseVector([5.1, 3.8, 1.6, 0.2])),\n",
       " Row(species='Setosa', label=0.0, features=DenseVector([5.1, 3.8, 1.9, 0.4])),\n",
       " Row(species='Versicolor', label=1.0, features=DenseVector([5.9, 3.0, 4.2, 1.5])),\n",
       " Row(species='Versicolor', label=1.0, features=DenseVector([5.8, 2.7, 3.9, 1.2])),\n",
       " Row(species='Versicolor', label=1.0, features=DenseVector([6.8, 2.8, 4.8, 1.4])),\n",
       " Row(species='Versicolor', label=1.0, features=DenseVector([5.5, 2.6, 4.4, 1.2])),\n",
       " Row(species='Versicolor', label=1.0, features=DenseVector([5.7, 2.9, 4.2, 1.3])),\n",
       " Row(species='Versicolor', label=1.0, features=DenseVector([5.8, 2.6, 4.0, 1.2])),\n",
       " Row(species='Versicolor', label=1.0, features=DenseVector([6.1, 3.0, 4.6, 1.4])),\n",
       " Row(species='Virginica', label=2.0, features=DenseVector([5.8, 2.7, 5.1, 1.9])),\n",
       " Row(species='Virginica', label=2.0, features=DenseVector([6.3, 2.9, 5.6, 1.8])),\n",
       " Row(species='Virginica', label=2.0, features=DenseVector([7.6, 3.0, 6.6, 2.1])),\n",
       " Row(species='Virginica', label=2.0, features=DenseVector([6.3, 2.7, 4.9, 1.8])),\n",
       " Row(species='Virginica', label=2.0, features=DenseVector([6.5, 3.0, 5.5, 1.8])),\n",
       " Row(species='Virginica', label=2.0, features=DenseVector([6.7, 2.5, 5.8, 1.8])),\n",
       " Row(species='Virginica', label=2.0, features=DenseVector([7.2, 3.2, 6.0, 1.8])),\n",
       " Row(species='Virginica', label=2.0, features=DenseVector([7.7, 2.8, 6.7, 2.0])),\n",
       " Row(species='Virginica', label=2.0, features=DenseVector([6.0, 3.0, 4.8, 1.8])),\n",
       " Row(species='Virginica', label=2.0, features=DenseVector([6.5, 3.0, 5.2, 2.0])),\n",
       " Row(species='Virginica', label=2.0, features=DenseVector([6.7, 3.1, 5.6, 2.4])),\n",
       " Row(species='Virginica', label=2.0, features=DenseVector([6.8, 3.2, 5.9, 2.3])),\n",
       " Row(species='Virginica', label=2.0, features=DenseVector([7.4, 2.8, 6.1, 1.9])),\n",
       " Row(species='Virginica', label=2.0, features=DenseVector([7.9, 3.8, 6.4, 2.0]))]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"--------------------------------------------------------------------------\n",
    "Perform Machine Learning\n",
    "-------------------------------------------------------------------------\"\"\"\n",
    "\n",
    "#Split into training and testing data\n",
    "(trainingData, testData) = irisLpDf.randomSplit([0.8, 0.2], seed=42)\n",
    "trainingData.count()\n",
    "testData.count()\n",
    "testData.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "d3ed073b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.classification import DecisionTreeClassifier\n",
    "from pyspark.ml.classification import RandomForestClassifier\n",
    "from pyspark.ml.classification import GBTClassifier\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "\n",
    "#Create the model\n",
    "rfClassifier = RandomForestClassifier(maxDepth=3, labelCol=\"label\",\\\n",
    "                featuresCol=\"features\")\n",
    "dtClassifier = DecisionTreeClassifier(maxDepth=4, labelCol=\"label\",\\\n",
    "                featuresCol=\"features\")\n",
    "rfModel = rfClassifier.fit(trainingData)\n",
    "dtModel = dtClassifier.fit(trainingData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "0c1f0b55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision tree : (13, 4)\n",
      "RandomForest : (20, 'gini')\n"
     ]
    }
   ],
   "source": [
    "print(f\"Decision tree : {dtModel.numNodes, dtModel.depth}\")\n",
    "print(f\"RandomForest : {rfModel.getNumTrees, rfModel.getImpurity()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "de226915",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Predict on the test data\n",
    "predictions = dtModel.transform(testData)\n",
    "predictions2 = rfModel.transform(testData)\n",
    "#predictions.select(\"prediction\",\"species\",\"label\").collect()\n",
    "#predictions.select(\"prediction\",\"species\",\"label\").collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "5e48beb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision tree accuracy : 0.9705882352941176\n",
      "Random forest accuracy : 1.0\n"
     ]
    }
   ],
   "source": [
    "#Evaluate accuracy\n",
    "evaluator = MulticlassClassificationEvaluator(predictionCol=\"prediction\", \\\n",
    "                    labelCol=\"label\",metricName=\"accuracy\")\n",
    "print(f\"Decision tree accuracy : {evaluator.evaluate(predictions)}\") \n",
    "print(f\"Random forest accuracy : {evaluator.evaluate(predictions2)}\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "fa98212e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+----------+-----+\n",
      "|label|prediction|count|\n",
      "+-----+----------+-----+\n",
      "|  1.0|       1.0|    7|\n",
      "|  2.0|       2.0|   13|\n",
      "|  2.0|       1.0|    1|\n",
      "|  0.0|       0.0|   13|\n",
      "+-----+----------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Draw a confusion matrix\n",
    "predictions.groupBy(\"label\",\"prediction\").count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "cf5569dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.classification import OneVsRest\n",
    "\n",
    "gbClassifier = GBTClassifier(maxDepth=3, labelCol=\"label\",\\\n",
    "                featuresCol=\"features\")\n",
    "ovr = OneVsRest(classifier=gbClassifier)\n",
    "model = ovr.fit(trainingData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "1df4397c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 1388:>                                                       (0 + 8) / 8]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient Boosted tree accuracy : 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 1388:=================================================>      (7 + 1) / 8]\r",
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "predictions_ovr = model.transform(testData)\n",
    "evaluator_2 = MulticlassClassificationEvaluator(metricName=\"accuracy\")\n",
    "print(f\"Gradient Boosted tree accuracy : {evaluator_2.evaluate(predictions_ovr)}\") "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4ea756b",
   "metadata": {},
   "source": [
    "### Accuracy de chaque modèle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "ac4f11ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision tree accuracy : 0.9705882352941176\n",
      "Random forest accuracy : 1.0\n",
      "Gradient Boosted tree accuracy : 1.0\n"
     ]
    }
   ],
   "source": [
    "print(f\"Decision tree accuracy : {evaluator.evaluate(predictions)}\") \n",
    "print(f\"Random forest accuracy : {evaluator.evaluate(predictions2)}\") \n",
    "print(f\"Gradient Boosted tree accuracy : {evaluator_2.evaluate(predictions_ovr)}\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43a2f562",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
