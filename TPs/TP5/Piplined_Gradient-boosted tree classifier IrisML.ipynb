{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark\n",
    "from pyspark import SparkContext\n",
    "from pyspark.sql import Row\n",
    "from pyspark.sql import SQLContext\n",
    "from pyspark import SparkFiles\n",
    "import os\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/spark/python/pyspark/sql/context.py:77: FutureWarning: Deprecated in 3.0.0. Use SparkSession.builder.getOrCreate() instead.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "\"\"\"----------------------------------------------------------------------------\n",
    "CREATE SPARK CONTEXT\n",
    "CREATE SQL CONTEXT\n",
    "----------------------------------------------------------------------------\"\"\"\n",
    "sc = SparkContext.getOrCreate()\n",
    "#sc =SparkContext()\n",
    "sqlContext = SQLContext(sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     sepal_length  sepal_width  petal_length  petal_width  variety_Setosa  \\\n",
      "0             5.1          3.5           1.4          0.2               1   \n",
      "1             4.9          3.0           1.4          0.2               1   \n",
      "2             4.7          3.2           1.3          0.2               1   \n",
      "3             4.6          3.1           1.5          0.2               1   \n",
      "4             5.0          3.6           1.4          0.2               1   \n",
      "..            ...          ...           ...          ...             ...   \n",
      "145           6.7          3.0           5.2          2.3               0   \n",
      "146           6.3          2.5           5.0          1.9               0   \n",
      "147           6.5          3.0           5.2          2.0               0   \n",
      "148           6.2          3.4           5.4          2.3               0   \n",
      "149           5.9          3.0           5.1          1.8               0   \n",
      "\n",
      "     variety_Versicolor  variety_Virginica  \n",
      "0                     0                  0  \n",
      "1                     0                  0  \n",
      "2                     0                  0  \n",
      "3                     0                  0  \n",
      "4                     0                  0  \n",
      "..                  ...                ...  \n",
      "145                   0                  1  \n",
      "146                   0                  1  \n",
      "147                   0                  1  \n",
      "148                   0                  1  \n",
      "149                   0                  1  \n",
      "\n",
      "[150 rows x 7 columns]\n"
     ]
    }
   ],
   "source": [
    "#data_dir=\"/work/irlin355_1/gratienj/ParallelProgrammingCourse/BigDataHadoopSpark/TPs/data\"\n",
    "#file = os.path.join(data_dir,\"iris.csv\")\n",
    "df = pd.read_csv(\"iris.csv\")\n",
    "panda_df = pd.get_dummies(df)\n",
    "#panda_df.round()\n",
    "#print(df_one)\n",
    "print(panda_df)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- sepal_length: double (nullable = true)\n",
      " |-- sepal_width: double (nullable = true)\n",
      " |-- petal_length: double (nullable = true)\n",
      " |-- petal_width: double (nullable = true)\n",
      " |-- variety_Setosa: long (nullable = true)\n",
      " |-- variety_Versicolor: long (nullable = true)\n",
      " |-- variety_Virginica: long (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "iris_df=sqlContext.createDataFrame(panda_df)\n",
    "iris_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- sepal_length: double (nullable = true)\n",
      " |-- sepal_width: double (nullable = true)\n",
      " |-- petal_length: double (nullable = true)\n",
      " |-- petal_width: double (nullable = true)\n",
      " |-- variety_Setosa: long (nullable = true)\n",
      " |-- variety_Versicolor: long (nullable = true)\n",
      " |-- variety_Virginica: long (nullable = true)\n",
      " |-- ind_variety: double (nullable = false)\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[Row(variety_Setosa=1, ind_variety=1.0),\n",
       " Row(variety_Setosa=0, ind_variety=0.0)]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Add a numeric indexer for the label/target column\n",
    "from pyspark.ml.feature import StringIndexer\n",
    "stringIndexer = StringIndexer(inputCol=\"variety_Setosa\", outputCol=\"ind_variety\")\n",
    "si_model = stringIndexer.fit(iris_df)\n",
    "\n",
    "irisNormDf = si_model.transform(iris_df)\n",
    "irisNormDf.printSchema()\n",
    "irisNormDf.select(\"variety_Setosa\",\"ind_variety\").distinct().collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------------------+------------------+------------------+------------------+-------------------+-------------------+-------------------+-------------------+\n",
      "|summary|      sepal_length|       sepal_width|      petal_length|       petal_width|     variety_Setosa| variety_Versicolor|  variety_Virginica|        ind_variety|\n",
      "+-------+------------------+------------------+------------------+------------------+-------------------+-------------------+-------------------+-------------------+\n",
      "|  count|               150|               150|               150|               150|                150|                150|                150|                150|\n",
      "|   mean| 5.843333333333334|3.0573333333333332|3.7580000000000005|1.1993333333333331| 0.3333333333333333| 0.3333333333333333| 0.3333333333333333| 0.3333333333333333|\n",
      "| stddev|0.8280661279778632|0.4358662849366984| 1.765298233259466|0.7622376689603464|0.47298376984040214|0.47298376984040214|0.47298376984040214|0.47298376984040214|\n",
      "|    min|               4.3|               2.0|               1.0|               0.1|                  0|                  0|                  0|                0.0|\n",
      "|    max|               7.9|               4.4|               6.9|               2.5|                  1|                  1|                  1|                1.0|\n",
      "+-------+------------------+------------------+------------------+------------------+-------------------+-------------------+-------------------+-------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\"\"\"--------------------------------------------------------------------------\n",
    "Perform Data Analytics\n",
    "-------------------------------------------------------------------------\"\"\"\n",
    "\n",
    "#See standard parameters\n",
    "irisNormDf.describe().show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----+-----------------+\n",
      "|species|label|         features|\n",
      "+-------+-----+-----------------+\n",
      "|      1|  1.0|[5.1,3.5,1.4,0.2]|\n",
      "|      1|  1.0|[4.9,3.0,1.4,0.2]|\n",
      "|      1|  1.0|[4.7,3.2,1.3,0.2]|\n",
      "|      1|  1.0|[4.6,3.1,1.5,0.2]|\n",
      "|      1|  1.0|[5.0,3.6,1.4,0.2]|\n",
      "|      1|  1.0|[5.4,3.9,1.7,0.4]|\n",
      "|      1|  1.0|[4.6,3.4,1.4,0.3]|\n",
      "|      1|  1.0|[5.0,3.4,1.5,0.2]|\n",
      "|      1|  1.0|[4.4,2.9,1.4,0.2]|\n",
      "|      1|  1.0|[4.9,3.1,1.5,0.1]|\n",
      "|      1|  1.0|[5.4,3.7,1.5,0.2]|\n",
      "|      1|  1.0|[4.8,3.4,1.6,0.2]|\n",
      "|      1|  1.0|[4.8,3.0,1.4,0.1]|\n",
      "|      1|  1.0|[4.3,3.0,1.1,0.1]|\n",
      "|      1|  1.0|[5.8,4.0,1.2,0.2]|\n",
      "|      1|  1.0|[5.7,4.4,1.5,0.4]|\n",
      "|      1|  1.0|[5.4,3.9,1.3,0.4]|\n",
      "|      1|  1.0|[5.1,3.5,1.4,0.3]|\n",
      "|      1|  1.0|[5.7,3.8,1.7,0.3]|\n",
      "|      1|  1.0|[5.1,3.8,1.5,0.3]|\n",
      "|      1|  1.0|[5.4,3.4,1.7,0.2]|\n",
      "|      1|  1.0|[5.1,3.7,1.5,0.4]|\n",
      "|      1|  1.0|[4.6,3.6,1.0,0.2]|\n",
      "|      1|  1.0|[5.1,3.3,1.7,0.5]|\n",
      "|      1|  1.0|[4.8,3.4,1.9,0.2]|\n",
      "|      1|  1.0|[5.0,3.0,1.6,0.2]|\n",
      "|      1|  1.0|[5.0,3.4,1.6,0.4]|\n",
      "|      1|  1.0|[5.2,3.5,1.5,0.2]|\n",
      "|      1|  1.0|[5.2,3.4,1.4,0.2]|\n",
      "|      1|  1.0|[4.7,3.2,1.6,0.2]|\n",
      "|      1|  1.0|[4.8,3.1,1.6,0.2]|\n",
      "|      1|  1.0|[5.4,3.4,1.5,0.4]|\n",
      "|      1|  1.0|[5.2,4.1,1.5,0.1]|\n",
      "|      1|  1.0|[5.5,4.2,1.4,0.2]|\n",
      "|      1|  1.0|[4.9,3.1,1.5,0.2]|\n",
      "|      1|  1.0|[5.0,3.2,1.2,0.2]|\n",
      "|      1|  1.0|[5.5,3.5,1.3,0.2]|\n",
      "|      1|  1.0|[4.9,3.6,1.4,0.1]|\n",
      "|      1|  1.0|[4.4,3.0,1.3,0.2]|\n",
      "|      1|  1.0|[5.1,3.4,1.5,0.2]|\n",
      "|      1|  1.0|[5.0,3.5,1.3,0.3]|\n",
      "|      1|  1.0|[4.5,2.3,1.3,0.3]|\n",
      "|      1|  1.0|[4.4,3.2,1.3,0.2]|\n",
      "|      1|  1.0|[5.0,3.5,1.6,0.6]|\n",
      "|      1|  1.0|[5.1,3.8,1.9,0.4]|\n",
      "|      1|  1.0|[4.8,3.0,1.4,0.3]|\n",
      "|      1|  1.0|[5.1,3.8,1.6,0.2]|\n",
      "|      1|  1.0|[4.6,3.2,1.4,0.2]|\n",
      "|      1|  1.0|[5.3,3.7,1.5,0.2]|\n",
      "|      1|  1.0|[5.0,3.3,1.4,0.2]|\n",
      "+-------+-----+-----------------+\n",
      "only showing top 50 rows\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DataFrame[species: bigint, label: double, features: vector]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"--------------------------------------------------------------------------\n",
    "Prepare data for ML\n",
    "-------------------------------------------------------------------------\"\"\"\n",
    "\n",
    "#Transform to a Data Frame for input to Machine Learing\n",
    "#Drop columns that are not required (low correlation)\n",
    "\n",
    "from pyspark.ml.linalg import Vectors\n",
    "def transformToLabeledPoint(row) :\n",
    "    lp = ( row[\"variety_Setosa\"], row[\"ind_variety\"], \\\n",
    "                Vectors.dense([row[\"sepal_length\"],\\\n",
    "                        row[\"sepal_width\"], \\\n",
    "                        row[\"petal_length\"], \\\n",
    "                        row[\"petal_width\"]]))\n",
    "    return lp\n",
    "\n",
    "\n",
    "irisLp = irisNormDf.rdd.map(transformToLabeledPoint)\n",
    "irisLpDf = sqlContext.createDataFrame(irisLp,[\"species\",\"label\",\"features\"])\n",
    "\n",
    "irisLpDf.select(\"species\",\"label\",\"features\").show(50)\n",
    "irisLpDf.cache()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import VectorIndexer\n",
    "# Index labels, adding metadata to the label column.\n",
    "# Fit on whole dataset to include all labels in index.\n",
    "labelIndexer = StringIndexer(inputCol=\"label\", outputCol=\"indexedLabel\").fit(irisLpDf)\n",
    "featureIndexer = VectorIndexer(inputCol=\"features\", outputCol=\"indexedFeatures\", maxCategories=4).fit(irisLpDf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"--------------------------------------------------------------------------\n",
    "Perform Machine Learning\n",
    "-------------------------------------------------------------------------\"\"\"\n",
    "\n",
    "#Split into training and testing data\n",
    "(trainingData, testData) = irisLpDf.randomSplit([0.9, 0.1])\n",
    "# trainingData.count()\n",
    "# testData.count()\n",
    "# testData.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.classification import GBTClassifier\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "# Train a RandomForest model.\n",
    "gbt = GBTClassifier(labelCol=\"indexedLabel\", featuresCol=\"indexedFeatures\", maxIter=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from pyspark.ml.feature import IndexToString, StringIndexer, VectorIndexer\n",
    "\n",
    "# # Convert indexed labels back to original labels.\n",
    "# labelConverter = IndexToString(inputCol=\"prediction\", outputCol=\"predictedLabel\",\n",
    "#                                labels=labelIndexer.labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml import Pipeline\n",
    "# Chain indexers and GBT in a Pipeline\n",
    "pipeline = Pipeline(stages=[labelIndexer, featureIndexer, gbt])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train model.  This also runs the indexers.\n",
    "model = pipeline.fit(trainingData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(prediction=1.0, species=1, label=1.0),\n",
       " Row(prediction=1.0, species=1, label=1.0),\n",
       " Row(prediction=0.0, species=0, label=0.0),\n",
       " Row(prediction=1.0, species=1, label=1.0),\n",
       " Row(prediction=1.0, species=1, label=1.0),\n",
       " Row(prediction=0.0, species=0, label=0.0),\n",
       " Row(prediction=0.0, species=0, label=0.0),\n",
       " Row(prediction=0.0, species=0, label=0.0),\n",
       " Row(prediction=0.0, species=0, label=0.0),\n",
       " Row(prediction=0.0, species=0, label=0.0),\n",
       " Row(prediction=0.0, species=0, label=0.0),\n",
       " Row(prediction=0.0, species=0, label=0.0),\n",
       " Row(prediction=0.0, species=0, label=0.0),\n",
       " Row(prediction=0.0, species=0, label=0.0),\n",
       " Row(prediction=0.0, species=0, label=0.0),\n",
       " Row(prediction=0.0, species=0, label=0.0),\n",
       " Row(prediction=0.0, species=0, label=0.0)]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make predictions.\n",
    "predictions = model.transform(testData)\n",
    "predictions.select(\"prediction\",\"species\",\"label\").collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select example rows to display.\n",
    "# predictions.select(\"predictedLabel\", \"label\", \"features\").show(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Error = 0\n",
      "GBTClassificationModel: uid = GBTClassifier_b7570e8dea68, numTrees=10, numClasses=2, numFeatures=4\n"
     ]
    }
   ],
   "source": [
    "# Select (prediction, true label) and compute test error\n",
    "evaluator = MulticlassClassificationEvaluator(\n",
    "    labelCol=\"indexedLabel\", predictionCol=\"prediction\", metricName=\"accuracy\")\n",
    "accuracy = evaluator.evaluate(predictions)\n",
    "print(\"Test Error = %g\" % (1.0 - accuracy))\n",
    "\n",
    "rfModel = model.stages[2]\n",
    "print(rfModel)  # summary only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(prediction=1.0, species=1, label=1.0),\n",
       " Row(prediction=1.0, species=1, label=1.0),\n",
       " Row(prediction=0.0, species=0, label=0.0),\n",
       " Row(prediction=1.0, species=1, label=1.0),\n",
       " Row(prediction=1.0, species=1, label=1.0),\n",
       " Row(prediction=0.0, species=0, label=0.0),\n",
       " Row(prediction=0.0, species=0, label=0.0),\n",
       " Row(prediction=0.0, species=0, label=0.0),\n",
       " Row(prediction=0.0, species=0, label=0.0),\n",
       " Row(prediction=0.0, species=0, label=0.0),\n",
       " Row(prediction=0.0, species=0, label=0.0),\n",
       " Row(prediction=0.0, species=0, label=0.0),\n",
       " Row(prediction=0.0, species=0, label=0.0),\n",
       " Row(prediction=0.0, species=0, label=0.0),\n",
       " Row(prediction=0.0, species=0, label=0.0),\n",
       " Row(prediction=0.0, species=0, label=0.0),\n",
       " Row(prediction=0.0, species=0, label=0.0)]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Predict on the test data\n",
    "predictions.select(\"prediction\",\"species\",\"label\").collect()\n",
    "#predictions = rfModel.transform(testData)\n",
    "#predictions.select(\"prediction\",\"species\",\"label\").collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Evaluate accuracy\n",
    "evaluator = MulticlassClassificationEvaluator(predictionCol=\"prediction\", \\\n",
    "                    labelCol=\"label\",metricName=\"accuracy\")\n",
    "evaluator.evaluate(predictions)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+----------+-----+\n",
      "|label|prediction|count|\n",
      "+-----+----------+-----+\n",
      "|  1.0|       1.0|    4|\n",
      "|  0.0|       0.0|   13|\n",
      "+-----+----------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Draw a confusion matrix\n",
    "predictions.groupBy(\"label\",\"prediction\").count().show()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "ae770bb617818cf230fd1ffbbf0864674026fee100acc558b8dad184af6593f8"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
